const { exec } = require('child_process');
const util = require('util');
const execPromise = util.promisify(exec);

async function setup() {
  console.log('üöÄ Configurando servidor de IA para fitness...\n');
  
  try {
    // Verificar si Ollama est√° instalado
    console.log('üì¶ Verificando Ollama...');
    try {
      await execPromise('ollama --version');
      console.log('‚úÖ Ollama ya est√° instalado');
    } catch {
      console.log('‚ö†Ô∏è  Ollama no encontrado. Por favor instala desde: https://ollama.ai');
      console.log('   Ejecuta: winget install Ollama.Ollama');
      process.exit(1);
    }
    
    // Descargar modelos optimizados para tu hardware
    console.log('\nüì• Descargando modelos optimizados para CPU con 8GB RAM...');
    
    console.log('Descargando Gemma 2B (1.5GB, mejor para tu hardware)...');
    await execPromise('ollama pull gemma:2b');
    
    console.log('Descargando TinyLlama (637MB, respuestas ultra-r√°pidas)...');
    await execPromise('ollama pull tinyllama');
    
    console.log('\n‚ú® Configuraci√≥n completada!');
    console.log('Modelos disponibles:');
    console.log('  - gemma:2b (recomendado para an√°lisis complejos)');
    console.log('  - tinyllama (para respuestas r√°pidas)');
    console.log('\nEjecuta "npm start" para iniciar el servidor');
    
  } catch (error) {
    console.error('‚ùå Error durante la configuraci√≥n:', error.message);
    process.exit(1);
  }
}

setup();